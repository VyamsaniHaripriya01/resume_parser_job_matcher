{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8192f14-65bf-42e2-9599-27e692d8c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook path and go one level up\n",
    "notebook_dir = os.path.abspath(\"..\")\n",
    "scripts_dir = os.path.join(notebook_dir, \"scripts\")\n",
    "\n",
    "# Add scripts directory to Python path\n",
    "sys.path.append(scripts_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "412a90df-53c8-484e-87e3-7e5e5ab25799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_resume import extract_text_from_docx, extract_text_from_pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ff96cb-8570-44ab-914a-03be28b3c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Cleaned Resume Text (Preview):\n",
      " haripriya vyamsani email haripriyaemailcom phone 9998887777 summary data science enthusiast experience python machine learning web scraping skills python pandas numpy scikitlearn matplotlib selenium sql experience data analyst intern xyz solutions jan 2024 april 2024 education btech computer science\n",
      "\n",
      "ðŸ”¸ Cleaned JD Text (Preview):\n",
      " job title junior data scientist seeking passionate detailoriented junior data scientist join analytics team responsibilities clean preprocess structured unstructured data build evaluate machine learning models work endtoend data pipelines dashboards collaborate product engineering teams deliver insi\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "\n",
    "from parse_resume import extract_text_from_docx\n",
    "from text_cleaner import clean_text\n",
    "\n",
    "# Load and clean resume & job description\n",
    "resume_path = \"../data/resumes/sample_resume.docx\"\n",
    "jd_path = \"../data/job_descriptions/sample_job_description.docx\"\n",
    "\n",
    "resume_raw = extract_text_from_docx(resume_path)\n",
    "jd_raw = extract_text_from_docx(jd_path)\n",
    "\n",
    "resume_cleaned = clean_text(resume_raw)\n",
    "jd_cleaned = clean_text(jd_raw)\n",
    "\n",
    "print(\"ðŸ”¹ Cleaned Resume Text (Preview):\\n\", resume_cleaned[:300])\n",
    "print(\"\\nðŸ”¸ Cleaned JD Text (Preview):\\n\", jd_cleaned[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b3632d-cc82-4430-8428-d9f2a78e5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Resume Match Score: 26.29%\n"
     ]
    }
   ],
   "source": [
    "# Check the similarity in both resume and job desciption (by using TF-IDF) \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Prepare the corpus\n",
    "corpus = [resume_cleaned, jd_cleaned]\n",
    "\n",
    "# Vectorize using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "\n",
    "# Display result\n",
    "print(f\"ðŸ” Resume Match Score: {similarity * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba7631c9-a84b-4ec5-ad97-a4be580a2a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Match Tests:\n",
      "\n",
      "ML Resume vs ML JD: 17.41 %\n",
      "SQL Resume vs SQL JD: 32.17 %\n",
      "SQL Resume vs ML JD: 3.93 %\n"
     ]
    }
   ],
   "source": [
    "#This matching is done by TF-IDF where it sees the matchig word to word. It does not recognises the meaning of the word. Hence the matching % will be low for this.\n",
    "\n",
    "from job_matcher import get_match_score\n",
    "\n",
    "# Test with different resume and JD combinations\n",
    "print(\"âœ… Match Tests:\\n\")\n",
    "\n",
    "score = get_match_score(\"../data/resumes/resume_ml.docx\", \"../data/job_descriptions/jd_ml_engineer.docx\")\n",
    "print(\"ML Resume vs ML JD:\", score, \"%\")\n",
    "\n",
    "score = get_match_score(\"../data/resumes/resume_sql.docx\", \"../data/job_descriptions/jd_sql_specialist.docx\")\n",
    "print(\"SQL Resume vs SQL JD:\", score, \"%\")\n",
    "\n",
    "score = get_match_score(\"../data/resumes/resume_sql.docx\", \"../data/job_descriptions/jd_ml_engineer.docx\")\n",
    "print(\"SQL Resume vs ML JD:\", score, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00a5e22d-1a90-4bac-a890-c4ae1eb5f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT model -- check the similarity with the job description symantically (this kind of this does not happen in TF-IDF) \n",
    "\n",
    "from job_matcher import get_bert_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81019c5e-d3c9-4532-af06-4e296a2ddeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– BERT Match Score: 64.34%\n"
     ]
    }
   ],
   "source": [
    "# Compute BERT-based similarity\n",
    "score = get_bert_similarity(resume_cleaned, jd_cleaned)\n",
    "print(f\"ðŸ¤– BERT Match Score: {score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a04ad0-5861-4c22-9900-8ed295250b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– BERT Match Score (resume_ml.docx vs jd_ml_engineer.docx): 61.81%\n",
      "ðŸ¤– BERT Match Score (resume_ml.docx vs jd_sql_specialist.docx): 33.68%\n",
      "ðŸ¤– BERT Match Score (resume_sql.docx vs jd_ml_engineer.docx): 50.43%\n",
      "ðŸ¤– BERT Match Score (resume_sql.docx vs jd_sql_specialist.docx): 77.58%\n"
     ]
    }
   ],
   "source": [
    "#BERT Testing Block\n",
    "\n",
    "# Resume and JD file paths\n",
    "resume_files = [\n",
    "    \"../data/resumes/resume_ml.docx\",\n",
    "    \"../data/resumes/resume_sql.docx\"\n",
    "]\n",
    "\n",
    "jd_files = [\n",
    "    \"../data/job_descriptions/jd_ml_engineer.docx\",\n",
    "    \"../data/job_descriptions/jd_sql_specialist.docx\"\n",
    "]\n",
    "\n",
    "# Test BERT similarity between each resume and each JD\n",
    "for resume in resume_files:\n",
    "    for jd in jd_files:\n",
    "        # Extract and clean raw text\n",
    "        resume_raw = extract_text_from_docx(resume)\n",
    "        jd_raw = extract_text_from_docx(jd)\n",
    "\n",
    "        resume_cleaned = clean_text(resume_raw)\n",
    "        jd_cleaned = clean_text(jd_raw)\n",
    "\n",
    "        # Calculate BERT-based similarity\n",
    "        score = get_bert_similarity(resume_cleaned, jd_cleaned)\n",
    "\n",
    "        # Display result\n",
    "        print(f\"ðŸ¤– BERT Match Score ({os.path.basename(resume)} vs {os.path.basename(jd)}): {score}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e35d854d-b9af-49ae-9ddc-0e3364886a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Important JD Keywords: ['analyst' 'bi' 'collaborate' 'create' 'experience' 'power' 'reporting'\n",
      " 'sql' 'tableau' 'using']\n",
      "ðŸŽ¯ Matched Important JD Keywords in Resume: ['analyst', 'experience', 'reporting', 'sql', 'tableau', 'using']\n"
     ]
    }
   ],
   "source": [
    "# Extracting important matched keywords from given resume and JD\n",
    "\n",
    "from job_matcher import extract_top_keywords\n",
    "\n",
    "\n",
    "# Extract top keywords from JD\n",
    "top_keywords = extract_top_keywords(jd_cleaned, top_n=10)\n",
    "print(\"ðŸ“Œ Important JD Keywords:\", top_keywords)\n",
    "\n",
    "# Find overlap with resume\n",
    "resume_tokens = set(resume_cleaned.lower().split())\n",
    "matched_keywords = [kw for kw in top_keywords if kw.lower() in resume_tokens]\n",
    "print(\"ðŸŽ¯ Matched Important JD Keywords in Resume:\", matched_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f903266-f2a9-4efe-bce7-f76508865ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Extracted Info:\n",
      "Name: Name: Ananya Reddy\n",
      "Email: ananya.reddy@email.com\n",
      "Phone: 987-654-3210\n",
      "Experience_summary: ['Machine Learning enthusiast with experience in predictive modeling and neural networks.', 'Experience:']\n"
     ]
    }
   ],
   "source": [
    "# Extracting candidate info from the resume.\n",
    "\n",
    "from parse_resume import extract_text_from_docx, extract_candidate_info\n",
    "\n",
    "resume_raw = extract_text_from_docx(\"../data/resumes/resume_ml.docx\")\n",
    "info = extract_candidate_info(resume_raw)\n",
    "\n",
    "print(\"ðŸ“Œ Extracted Info:\")\n",
    "for key, value in info.items():\n",
    "    print(f\"{key.capitalize()}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f329f67-64d1-463d-8f91-3710d122d5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hpriy\\onedrive\\desktop\\hari's\\ds\\projects\\resume_parser_job_matcher\\venv\\lib\\site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hpriy\\onedrive\\desktop\\hari's\\ds\\projects\\resume_parser_job_matcher\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hpriy\\onedrive\\desktop\\hari's\\ds\\projects\\resume_parser_job_matcher\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.0 MB 1.6 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.1/11.0 MB 1.7 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.2/11.0 MB 1.5 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.3/11.0 MB 1.8 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/11.0 MB 1.8 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/11.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/11.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.8/11.0 MB 1.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.9/11.0 MB 2.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.0/11.0 MB 2.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.1/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 2.3 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.7/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.0/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.2/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.3/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.5/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.7/11.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.4/11.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.6/11.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.4/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.0/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.1/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.3/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.5/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.6/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.8/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.0/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.7/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.8/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.0/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.1/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.3/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.5/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.3/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.6/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.0/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.1/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.6/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.3/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "   ---------------------------------------- 0.0/509.2 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 71.7/509.2 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 194.6/509.2 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 358.4/509.2 kB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 471.0/509.2 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 509.2/509.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "   ---------------------------------------- 0.0/347.8 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 204.8/347.8 kB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 337.9/347.8 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 347.8/347.8 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bae01f9-e872-4e9b-948b-47e7d0275543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined code of BERT Matching, Key word extraction and Candidate Info extraction\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "resume_files = [f for f in glob.glob(\"../data/resumes/*.docx\") if not os.path.basename(f).startswith('~$')]\n",
    "jd_files = [f for f in glob.glob(\"../data/job_descriptions/*.docx\") if not os.path.basename(f).startswith('~$')]\n",
    "\n",
    "for resume_path in resume_files:\n",
    "    for jd_path in jd_files:\n",
    "        # Extract and clean text\n",
    "        resume_raw = extract_text_from_docx(resume_path)\n",
    "        jd_raw = extract_text_from_docx(jd_path)\n",
    "        resume_cleaned = clean_text(resume_raw)\n",
    "        jd_cleaned = clean_text(jd_raw)\n",
    "\n",
    "        # Extract candidate info\n",
    "        info = extract_candidate_info(resume_raw)\n",
    "\n",
    "        # Extract important JD keywords\n",
    "        jd_keywords = extract_top_keywords(jd_cleaned, top_n=10)\n",
    "        matched_keywords = [kw for kw in jd_keywords if kw.lower() in resume_cleaned.lower()]\n",
    "\n",
    "        # Compute BERT match score\n",
    "        score = get_bert_similarity(resume_cleaned, jd_cleaned)\n",
    "\n",
    "        # Append result to list\n",
    "        results.append({\n",
    "            \"Resume\": os.path.basename(resume_path),\n",
    "            \"Job Description\": os.path.basename(jd_path),\n",
    "            \"Candidate Name\": info.get(\"name\"),\n",
    "            \"Email\": info.get(\"email\"),\n",
    "            \"Phone\": info.get(\"phone\"),\n",
    "            \"Experience Summary\": \" | \".join(info.get(\"experience_summary\", [])),\n",
    "            \"BERT Match Score (%)\": score,\n",
    "            \"Matched JD Keywords\": \", \".join(matched_keywords)\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1417b5d-d60b-44cb-a3c0-daab3791abd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Results saved to resume_match_results.csv\n"
     ]
    }
   ],
   "source": [
    "#Creating a data frame and saving the data to csv\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"../data/resume_match_results.csv\", index=False)\n",
    "print(\"âœ… Results saved to resume_match_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5dea3-4c43-45c3-aa66-ccc7a8d59150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
